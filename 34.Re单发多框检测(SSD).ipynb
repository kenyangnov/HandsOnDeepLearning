{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单发多框检测是一个多尺度的目标检测模型\n",
    "\n",
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import autograd, contrib, gluon, image, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别预测层\n",
    "\n",
    "# 设目标的类别个数为q，每个锚框的类别个数将是q+1，其中类别0表示锚框只包含背景。\n",
    "# 在某个尺度下，设特征图的高和宽分别为h、w，如果以其中每个单元为中心生成a个锚框，那么我们需要对hwa个锚框进行分类\n",
    "# 若使用全连接层作为输出， 很容易导致模型参数过多\n",
    "# 因此，使用NiN中介绍的使用卷积层的通道来输出类别预测的方法，降低模型复杂度\n",
    "# 下面定义一个类别预测层\n",
    "\n",
    "def cls_predictor(num_anchors, num_classes):\n",
    "    return nn.Conv2D(num_anchors * (num_classes + 1), kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 边界框预测层\n",
    "\n",
    "def bbox_predictor(num_anchors):\n",
    "    return nn.Conv2D(num_anchors * 4, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 55, 20, 20), (2, 33, 10, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个尺度上特征图的形状或以同一单元为中心生成的锚框个数都可能不同，因此不同尺度的预测输出形状可能不同\n",
    "\n",
    "def forward(x, block):\n",
    "    block.initialize()\n",
    "    return block(x)\n",
    "\n",
    "Y1 = forward(nd.zeros((2, 8, 20, 20)), cls_predictor(5, 10))\n",
    "Y2 = forward(nd.zeros((2, 16, 10, 10)), cls_predictor(3, 10))\n",
    "(Y1.shape, Y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通道维包含中心相同的锚框的预测结果，首先将通道维移到最后一维。\n",
    "# 因为不同尺度下批量大小仍保持不变，我们可以将预测结果转换成二维的(批量大小, 高 × 宽 × 通道数)的格式，以方便之后在维度1上的连结\n",
    "def flatten_pred(pred):\n",
    "    return pred.transpose((0, 2, 3, 1)).flatten()\n",
    "\n",
    "def concat_preds(preds):\n",
    "    return nd.concat(*[flatten_pred(p) for p in preds], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 25300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 连结多尺度的预测结果\n",
    "concat_preds([Y1, Y2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 10, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是高和宽减半块（为了在多尺度检测目标）\n",
    "# 串联了两个填充为1的 3×3 卷积层和步幅为2的 2×2 最大池化层\n",
    "# 由于1×2+(3−1)+(3−1)=6，输出特征图中每个单元在输入特征图上的感受野形状为6×6\n",
    "def down_sample_blk(num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    for _ in range(2):\n",
    "        blk.add(nn.Conv2D(num_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm(in_channels=num_channels),\n",
    "                nn.Activation('relu'))\n",
    "    blk.add(nn.MaxPool2D(2))\n",
    "    return blk\n",
    "\n",
    "# 测试高和宽减半块的前向计算。可以看到，它改变了输入的通道数，并将高和宽减半\n",
    "forward(nd.zeros((2, 3, 20, 20)), down_sample_blk(10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 32, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基础网络块\n",
    "# 该网络串联3个高和宽减半块，并逐步将通道数翻倍。\n",
    "# 当输入的原始图像的形状为256×256时，基础网络块输出的特征图的形状为32×32\n",
    "def base_net():\n",
    "    blk = nn.Sequential()\n",
    "    for num_filters in [16, 32, 64]:\n",
    "        blk.add(down_sample_blk(num_filters))\n",
    "    return blk\n",
    "\n",
    "forward(nd.zeros((2, 3, 256, 256)), base_net()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSD模型一共包含5个模块，每个模块输出的特征图既用来生成锚框，又用来预测这些锚框的类别和偏移量\n",
    "# 第一模块为基础网络块，第二模块至第四模块为高和宽减半块，第五模块使用全局最大池化层将高和宽降到1。\n",
    "# 因此第二模块至第五模块均为多尺度特征块\n",
    "\n",
    "def get_blk(i):\n",
    "    if i == 0:\n",
    "        blk = base_net()\n",
    "    elif i == 4:\n",
    "        blk = nn.GlobalAvgPool2D()\n",
    "    else:\n",
    "        blk = down_sample_blk(128)\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义每个模块前向计算\n",
    "# 这里不仅返回卷积计算输出的特征图Y，还返回根据Y生成的当前尺度的锚框，以及基于Y预测的锚框类别和偏移量\n",
    "\n",
    "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
    "    Y = blk(X)\n",
    "    anchors = contrib.ndarray.MultiBoxPrior(Y, sizes=size, ratios=ratio)\n",
    "    cls_preds = cls_predictor(Y)\n",
    "    bbox_preds = bbox_predictor(Y)\n",
    "    return (Y, anchors, cls_preds, bbox_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定超参数\n",
    "# 靠近顶部的多尺度特征块用来检测尺寸较大的目标，因此需要生成较大的锚框\n",
    "# 先将0.2到1.05之间均分5份，以确定不同尺度下锚框大小的较小值0.2、0.37、0.54等，\n",
    "# 再按sqrt(0.2×0.37)=0.272、sqrt(0.37×0.54)=0.447等来确定不同尺度下锚框大小的较大值。\n",
    "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79], [0.88, 0.961]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "num_anchors = len(sizes[0]) + len(ratios[0]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整TinySSD模型\n",
    "class TinySSD(nn.Block):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(TinySSD, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        for i in range(5):\n",
    "            # 即赋值语句self.blk_i = get_blk(i)\n",
    "            setattr(self, 'blk_%d' % i, get_blk(i))\n",
    "            setattr(self, 'cls_%d' % i, cls_predictor(num_anchors,\n",
    "                                                      num_classes))\n",
    "            setattr(self, 'bbox_%d' % i, bbox_predictor(num_anchors))\n",
    "\n",
    "    def forward(self, X):\n",
    "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
    "        for i in range(5):\n",
    "            # getattr(self, 'blk_%d' % i)即访问self.blk_i\n",
    "            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(\n",
    "                X, getattr(self, 'blk_%d' % i), sizes[i], ratios[i],\n",
    "                getattr(self, 'cls_%d' % i), getattr(self, 'bbox_%d' % i))\n",
    "        # reshape函数中的0表示保持批量大小不变\n",
    "        return (nd.concat(*anchors, dim=1),\n",
    "                concat_preds(cls_preds).reshape((0, -1, self.num_classes + 1)), \n",
    "                concat_preds(bbox_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output anchors: (1, 5444, 4)\n",
      "output class preds: (32, 5444, 2)\n",
      "output bbox preds: (32, 21776)\n"
     ]
    }
   ],
   "source": [
    "net = TinySSD(num_classes=1)\n",
    "net.initialize()\n",
    "X = nd.zeros((32, 3, 256, 256))\n",
    "anchors, cls_preds, bbox_preds = net(X)\n",
    "\n",
    "print('output anchors:', anchors.shape)\n",
    "print('output class preds:', cls_preds.shape)\n",
    "print('output bbox preds:', bbox_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/pikachu\\train.rec from https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/train.rec...\n",
      "Downloading ../data/pikachu\\train.idx from https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/train.idx...\n",
      "Downloading ../data/pikachu\\val.rec from https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/val.rec...\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "batch_size = 32\n",
    "train_iter, _ = d2l.load_data_pikachu(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx, net = d2l.try_gpu(), TinySSD(num_classes=1)\n",
    "net.initialize(init=init.Xavier(), ctx=ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd',\n",
    "                        {'learning_rate': 0.2, 'wd': 5e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和评价函数\n",
    "\n",
    "# 目标检测有两个损失：\n",
    "# 1.锚框类别损失（使用图像分类问题一直使用的交叉熵损失函数）\n",
    "# 2.正类锚框偏移量的损失（使用L1范数损失，即预测值与真实值差的绝对值）\n",
    "# 掩码变量bbox_masks令负类锚框和填充锚框不参与损失的计算\n",
    "# 最后将有关锚框类别和偏移量的损失相加得到模型的最终损失函数\n",
    "cls_loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "bbox_loss = gloss.L1Loss()\n",
    "\n",
    "def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks):\n",
    "    cls = cls_loss(cls_preds, cls_labels)\n",
    "    bbox = bbox_loss(bbox_preds * bbox_masks, bbox_labels * bbox_masks)\n",
    "    return cls + bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里可以沿用准确率评价分类结果。因为使用L1范数损失，使用平均绝对误差评价边界框的预测结果\n",
    "def cls_eval(cls_preds, cls_labels):\n",
    "    # 由于类别预测结果放在最后一维，argmax需要指定最后一维\n",
    "    return (cls_preds.argmax(axis=-1) == cls_labels).sum().asscalar()\n",
    "\n",
    "def bbox_eval(bbox_pred, bbox_labels, bbox_masks):\n",
    "    return ((bbox_labels - bbox_pred) * bbox_masks).abs().sum().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "for epoch in range(20):\n",
    "    acc_sum, mae_sum, n, m = 0.0, 0.0, 0, 0\n",
    "    train_iter.reset()  # 从头读取数据\n",
    "    start = time.time()\n",
    "    for batch in train_iter:\n",
    "        X = batch.data[0].as_in_context(ctx)\n",
    "        Y = batch.label[0].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            # 生成多尺度的锚框，为每个锚框预测类别和偏移量\n",
    "            anchors, cls_preds, bbox_preds = net(X)\n",
    "            # 为每个锚框标注类别和偏移量\n",
    "            bbox_labels, bbox_masks, cls_labels = contrib.nd.MultiBoxTarget(\n",
    "                anchors, Y, cls_preds.transpose((0, 2, 1)))\n",
    "            # 根据类别和偏移量的预测和标注值计算损失函数\n",
    "            l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,\n",
    "                          bbox_masks)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "        acc_sum += cls_eval(cls_preds, cls_labels)\n",
    "        n += cls_labels.size\n",
    "        mae_sum += bbox_eval(bbox_preds, bbox_labels, bbox_masks)\n",
    "        m += bbox_labels.size\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch %2d, class err %.2e, bbox mae %.2e, time %.1f sec' % (\n",
    "            epoch + 1, 1 - acc_sum / n, mae_sum / m, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试图像，并变换尺寸和维度\n",
    "img = image.imread('../img/pikachu.jpg')\n",
    "feature = image.imresize(img, 256, 256).astype('float32')\n",
    "X = feature.transpose((2, 0, 1)).expand_dims(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过MultiBoxDetection函数根据锚框及其预测偏移量得到预测边界框，并通过非极大值抑制移除相似的预测边界框\n",
    "def predict(X):\n",
    "    anchors, cls_preds, bbox_preds = net(X.as_in_context(ctx))\n",
    "    cls_probs = cls_preds.softmax().transpose((0, 2, 1))\n",
    "    output = contrib.nd.MultiBoxDetection(cls_probs, bbox_preds, anchors)\n",
    "    idx = [i for i, row in enumerate(output[0]) if row[0].asscalar() != -1]\n",
    "    return output[0, idx]\n",
    "\n",
    "output = predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将置信度不低于0.3的边界框筛选为最终输出用以展示\n",
    "d2l.set_figsize((5, 5))\n",
    "\n",
    "def display(img, output, threshold):\n",
    "    fig = d2l.plt.imshow(img.asnumpy())\n",
    "    for row in output:\n",
    "        score = row[1].asscalar()\n",
    "        if score < threshold:\n",
    "            continue\n",
    "        h, w = img.shape[0:2]\n",
    "        bbox = [row[2:6] * nd.array((w, h, w, h), ctx=row.context)]\n",
    "        d2l.show_bboxes(fig.axes, bbox, '%.2f' % score, 'w')\n",
    "\n",
    "display(img, output, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可优化的方向\n",
    "# 1.将L1范数损失替换为平滑L1损失\n",
    "# 2.目标在图片中较小时，模型常采用比较大的输入图像尺寸\n",
    "# 3.为锚框标注类别时，通常产生大量的负类锚框，可以对负类锚框进行采样从而使数据类别更加平衡\n",
    "# 4.在损失函数中为有关锚框类别和有关正类锚框偏移量的损失分别赋予不同的权重超参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
