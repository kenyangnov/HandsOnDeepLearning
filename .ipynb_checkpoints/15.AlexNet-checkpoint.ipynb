{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet与LeNet区别：\n",
    "# 1.AlexNet包含8层变换（5卷积层+2全连接隐藏层+1全连接输出层）\n",
    "# 2.AlexNet将sigmoid激活函数改为ReLU激活函数（计算简单且不同参数初始化方法下是模型更易训练）\n",
    "# 3.AlexNet使用丢弃法控制全连接层的模型复杂度\n",
    "# 4.AlexNet引入了大量的图像增广（反转、裁剪和颜色变化），进一步扩大数据集来缓解过拟合\n",
    "\n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, nn\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "# 使用较大的11×11窗口来捕获物体，同时使用步幅4来较大幅度减小输出高和宽。这里使用的输出通道数比LeNet中也大很多\n",
    "net.add(nn.Conv2D(96, kernel_size=11, strides=4, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "        nn.Conv2D(256, kernel_size=5, padding=1, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 连续3个卷积层，且使用更小的卷积窗口，除了最后的卷积层外，进一步增大了输出通道数。\n",
    "        # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 这里全连接层的输出个数比LeNet大数倍，使用丢弃层来缓解过拟合\n",
    "        nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
    "        nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
    "        # 输出层。由于使用Fashion-MNIST,所以类别数为10\n",
    "        nn.Dense(10)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 output shape:\t (1, 96, 54, 54)\n",
      "pool0 output shape:\t (1, 96, 26, 26)\n",
      "conv1 output shape:\t (1, 256, 24, 24)\n",
      "pool1 output shape:\t (1, 256, 11, 11)\n",
      "conv2 output shape:\t (1, 384, 11, 11)\n",
      "conv3 output shape:\t (1, 384, 11, 11)\n",
      "conv4 output shape:\t (1, 256, 11, 11)\n",
      "pool2 output shape:\t (1, 256, 5, 5)\n",
      "dense0 output shape:\t (1, 4096)\n",
      "dropout0 output shape:\t (1, 4096)\n",
      "dense1 output shape:\t (1, 4096)\n",
      "dropout1 output shape:\t (1, 4096)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = nd.random.uniform(shape = (1, 1, 224, 224))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。这个可以通过Resize实例来实现。\n",
    "# 也就是说，我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调用\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n",
    "        '~', '.mxnet', 'datasets', 'fashion-mnist')):\n",
    "    root = os.path.expanduser(root)  # 展开用户路径'~'\n",
    "    transformer = []\n",
    "    if resize:\n",
    "        transformer += [gdata.vision.transforms.Resize(resize)]\n",
    "    transformer += [gdata.vision.transforms.ToTensor()]\n",
    "    transformer = gdata.vision.transforms.Compose(transformer)\n",
    "    mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n",
    "    mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "    train_iter = gdata.DataLoader(\n",
    "        mnist_train.transform_first(transformer), batch_size, shuffle=True,\n",
    "        num_workers=num_workers)\n",
    "    test_iter = gdata.DataLoader(\n",
    "        mnist_test.transform_first(transformer), batch_size, shuffle=False,\n",
    "        num_workers=num_workers)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
