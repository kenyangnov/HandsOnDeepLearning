{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  R-CNN:\n",
    "#     1.对输入图像使用选择性搜索(selective search)来选取多个高质量的提议区域。\n",
    "#       这些提议区域通常是在多个尺度下选取的，并具有不同的形状和大小。\n",
    "#       每个提议区域将被标注类别和真实边界框\n",
    "#     2.选取一个预训练的卷积神经网络，并将其在输出层之前截断。\n",
    "#       将每个提议区域变形为网络需要的输入尺寸，并通过前向计算输出抽取的提议区域特征。\n",
    "#     3.将每个提议区域的特征连同其标注的类别作为一个样本，训练多个支持向量机对目标分类。\n",
    "#       其中每个支持向量机用来判断样本是否属于某一个类别。\n",
    "#     4.将每个提议区域的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框\n",
    "\n",
    "# R-CNN的主要性能瓶颈在于需要对每个提议区域独立抽取特征。\n",
    "# 由于这些区域通常有大量重叠，独立的特征抽取会导致大量的重复计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast R-CNN对R-CNN的一个主要改进在于只对整个图像做卷积神经网络的前向计算\n",
    "\n",
    "# Fast R-CNN：\n",
    "#     1.与R-CNN相比，Fast R-CNN用来提取特征的卷积神经网络的输入是整个图像，而不是各个提议区域。\n",
    "#       而且，这个网络通常会参与训练，即更新模型参数。\n",
    "#       设输入为一张图像，将卷积神经网络的输出的形状记为 1×c×h1×w1 。\n",
    "#     2.假设选择性搜索生成 n 个提议区域。\n",
    "#       这些形状各异的提议区域在卷积神经网络的输出上分别标出形状各异的兴趣区域。\n",
    "#       这些兴趣区域需要抽取出形状相同的特征（假设高和宽均分别指定为 h2 和 w2 ）以便于连结后输出。\n",
    "#       Fast R-CNN引入兴趣区域池化（region of interest pooling，RoI池化）层，\n",
    "#       将卷积神经网络的输出和提议区域作为输入，输出连结后的各个提议区域抽取的特征，形状为 n×c×h2×w2 。\n",
    "#     3.通过全连接层将输出形状变换为 n×d ，其中超参数 d 取决于模型设计\n",
    "#     4.预测类别时，将全连接层的输出的形状再变换为 n×q 并使用softmax回归（ q 为类别个数）。\n",
    "#       预测边界框时，将全连接层的输出的形状变换为 n×4 。\n",
    "#       也就是说，我们为每个提议区域预测类别和边界框\n",
    "\n",
    "# Fast R-CNN通常需要在选择性搜索中生成较多的提议区域，以获得较精确的目标检测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[  0.   1.   2.   3.]\n",
       "   [  4.   5.   6.   7.]\n",
       "   [  8.   9.  10.  11.]\n",
       "   [ 12.  13.  14.  15.]]]]\n",
       "<NDArray 1x1x4x4 @cpu(0)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RoI池化\n",
    "from mxnet import nd\n",
    "# 假设卷积神经网络抽取的特征X的高和宽均为4且只有单通道\n",
    "X = nd.arange(16).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设图像的高和宽均为40像素。\n",
    "# 再假设选择性搜索在图像上生成了两个提议区域：每个区域由5个元素表示，\n",
    "# 分别为区域目标类别、左上角的 x 和 y 轴坐标以及右下角的 x 和 y 轴坐标\n",
    "rois = nd.array([[0, 0, 0, 20, 20], [0, 0, 10, 30, 30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[  5.   6.]\n",
       "   [  9.  10.]]]\n",
       "\n",
       "\n",
       " [[[  9.  11.]\n",
       "   [ 13.  15.]]]]\n",
       "<NDArray 2x1x2x2 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于X的高和宽是图像的高和宽的1/10，\n",
    "# 以上两个提议区域中的坐标先按spatial_scale自乘0.1\n",
    "# 然后在X上分别标出兴趣区域X[:,:,0:3,0:3]和X[:,:,1:4,0:4] \n",
    "# 注意：此处是1:4,0:4，先确定y轴再到x轴，括号是一层一层的\n",
    "# 最后对这两个兴趣区域分别划分子窗口网格并抽取高和宽为2的特征\n",
    "\n",
    "nd.ROIPooling(X, rois, pooled_size=(2, 2), spatial_scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster R-CNN提出将选择性搜索替换成区域提议网络（region proposal network），\n",
    "# 从而减少提议区域的生成数量，并保证目标检测的精度\n",
    "\n",
    "# Faster R-CNN\n",
    "#  与Fast R-CNN相比，只有生成提议区域的方法从选择性搜索变成了区域提议网络，而其他部分均保持不变\n",
    "#  区域提议网络的计算步骤如下：\n",
    "#     1.使用填充为1的 3×3 卷积层变换卷积神经网络的输出，并将输出通道数记为 c 。\n",
    "#       这样，卷积神经网络为图像抽取的特征图中的每个单元均得到一个长度为 c 的新特征。\n",
    "#     2.以特征图每个单元为中心，生成多个不同大小和宽高比的锚框并标注它们\n",
    "#     3.用锚框中心单元长度为 c 的特征分别预测该锚框的二元类别（含目标还是背景）和边界框\n",
    "#     4.使用非极大值抑制，从预测类别为目标的预测边界框中移除相似的结果。\n",
    "#       最终输出的预测边界框即兴趣区域池化层所需要的提议区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask R-CNN\n",
    "# 如果训练数据还标注了每个目标在图像上的像素级位置，\n",
    "# 那么Mask R-CNN能有效利用这些详尽的标注信息进一步提升目标检测的精度\n",
    "# Mask R-CNN将兴趣区域池化层替换成了兴趣区域对齐层，\n",
    "# 即通过双线性插值（bilinear interpolation）来保留特征图上的空间信息，从而更适于像素级预测\n",
    "# 兴趣区域对齐层的输出包含了所有兴趣区域的形状相同的特征图\n",
    "# 它们既用来预测兴趣区域的类别和边界框，又通过额外的全卷积网络预测目标的像素级位置"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
